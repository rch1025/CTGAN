{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CTGAN module.\"\"\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2 \n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from packaging import version\n",
    "from torch import optim\n",
    "from torch.nn import BatchNorm1d, Dropout, LeakyReLU, Linear, Module, ReLU, Sequential, functional\n",
    "\n",
    "from PROGAN.data_sampler import DataSampler\n",
    "from PROGAN.data_transformer import DataTransformer\n",
    "from PROGAN.synthesizers.base import BaseSynthesizer, random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_data_sampler = DataSampler(\n",
    "    train_data,\n",
    "    self_transformer.output_info_list,\n",
    "    self_log_frequency)\n",
    "\n",
    "n_discrete_columns = sum([1 for column_info in self_transformer.output_info_list if is_discrete_column(column_info)])\n",
    "\n",
    "self_rid_by_cat_cols = []\n",
    "\n",
    "# Compute _rid_by_cat_cols\n",
    "st = 0\n",
    "for column_info in self_transformer.output_info_list:\n",
    "    if is_discrete_column(column_info):\n",
    "        span_info = column_info[0]\n",
    "        ed = st + span_info.dim\n",
    "\n",
    "        rid_by_cat = []\n",
    "        for j in range(span_info.dim):\n",
    "            rid_by_cat.append(np.nonzero(train_data[:, st + j])[0])\n",
    "        self_rid_by_cat_cols.append(rid_by_cat)\n",
    "        st = ed\n",
    "    else:\n",
    "        st += sum([span_info.dim for span_info in column_info])\n",
    "\n",
    "\n",
    "max_category = max([\n",
    "    column_info[0].dim\n",
    "    for column_info in self_transformer.output_info_list\n",
    "    if is_discrete_column(column_info)\n",
    "], default=0)\n",
    "\n",
    "\n",
    "self_discrete_column_cond_st = np.zeros(n_discrete_columns, dtype='int32')\n",
    "self_discrete_column_n_category = np.zeros(n_discrete_columns, dtype='int32')\n",
    "self_discrete_column_category_prob = np.zeros((n_discrete_columns, max_category))\n",
    "self_n_discrete_columns = n_discrete_columns\n",
    "\n",
    "\n",
    "# 범주형 변수의 모든 차원을 합친 것\n",
    "self_n_categories = sum([\n",
    "    column_info[0].dim\n",
    "    for column_info in self_transformer.output_info_list\n",
    "    if is_discrete_column(column_info)\n",
    "])\n",
    "\n",
    "st = 0\n",
    "current_id = 0\n",
    "current_cond_st = 0\n",
    "for column_info in self_transformer.output_info_list:\n",
    "    if is_discrete_column(column_info):\n",
    "        span_info = column_info[0]\n",
    "        ed = st + span_info.dim\n",
    "        category_freq = np.sum(train_data[:, st:ed], axis=0)\n",
    "        if log_frequency:\n",
    "            category_freq = np.log(category_freq + 1)\n",
    "        category_prob = category_freq / np.sum(category_freq)\n",
    "        self_discrete_column_category_prob[current_id, :span_info.dim] = category_prob\n",
    "        self_discrete_column_cond_st[current_id] = current_cond_st\n",
    "        self_discrete_column_n_category[current_id] = span_info.dim\n",
    "        current_cond_st += span_info.dim\n",
    "        current_id += 1\n",
    "        st = ed\n",
    "    else:\n",
    "        st += sum([span_info.dim for span_info in column_info])\n",
    "\n",
    "\n",
    "def is_discrete_column(column_info):\n",
    "    return (len(column_info) == 1\n",
    "            and column_info[0].activation_fn == 'softmax')\n",
    "\n",
    "\n",
    "def _random_choice_prob_index(discrete_column_id):\n",
    "    probs = self_discrete_column_category_prob[discrete_column_id]\n",
    "    r = np.expand_dims(np.random.rand(probs.shape[0]), axis=1)\n",
    "    return (probs.cumsum(axis=1) > r).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discrete_column_id : [ 2  3  3  5 10 10 13  9  7  0  2  4 13  5  7  7  4  7  6  1 13  6 13  0\n",
      " 10  3  6 11  9  0 12  2 10 10 10  1 11  9  2  2  9  7  9  6  8  4  5  9\n",
      "  3  9 12 13  5  8  1  9  6  5 10  9 11  6  9 12]\n",
      "self_n_categories : 71\n"
     ]
    }
   ],
   "source": [
    "batch = 64\n",
    "self_n_discrete_columns = 14\n",
    "self_n_categories = sum([\n",
    "    column_info[0].dim\n",
    "    for column_info in self_transformer.output_info_list\n",
    "    if is_discrete_column(column_info)\n",
    "])\n",
    "\n",
    "discrete_column_id = np.random.choice(\n",
    "    np.arange(self_n_discrete_columns), batch)\n",
    "\n",
    "print('discrete_column_id :', discrete_column_id)\n",
    "print('self_n_categories :', self_n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask : [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cond = np.zeros((batch, self_n_categories), dtype='float32')\n",
    "mask = np.zeros((batch, self_n_discrete_columns), dtype='float32')\n",
    "mask[np.arange(batch), discrete_column_id] = 1 # 랜덤으로 샘플링한 범주형 변수를 mask에 넣음\n",
    "print('mask :', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_choice_prob_index(discrete_column_id):\n",
    "    probs = self_discrete_column_category_prob[discrete_column_id]\n",
    "    r = np.expand_dims(np.random.rand(probs.shape[0]), axis=1)\n",
    "    return (probs.cumsum(axis=1) > r).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51289905, 0.48710095, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.24024464, 0.22571252, 0.21907306, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.24024464, 0.22571252, 0.21907306, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.1544552 , 0.22354369, 0.1680083 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.51647875, 0.48352125, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.16183598, 0.14813479, 0.11372476, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = self_discrete_column_category_prob[discrete_column_id]\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51289905, 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.24024464, 0.46595716, 0.68503022, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.24024464, 0.46595716, 0.68503022, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.1544552 , 0.37799888, 0.54600718, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.51647875, 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.16183598, 0.30997077, 0.42369553, ..., 1.        , 1.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.expand_dims(np.random.rand(probs.shape[0]), axis=1)\n",
    "\n",
    "probs.cumsum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_id_in_col : [0 0 1 2 0 1 7 0 0 1 0 4 4 1 0 0 1 0 4 1 5 1 4 1 1 2 2 8 0 1 1 0 1 1 1 1 1\n",
      " 1 0 1 0 0 1 0 1 3 4 1 1 1 3 1 0 1 0 0 0 2 1 0 5 0 0 4]\n"
     ]
    }
   ],
   "source": [
    "category_id_in_col = _random_choice_prob_index(discrete_column_id)\n",
    "print('category_id_in_col :', category_id_in_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "category_id = (self_discrete_column_cond_st[discrete_column_id] + category_id_in_col)\n",
    "cond[np.arange(batch), category_id] = 1\n",
    "cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 71)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Module):\n",
    "    \"\"\"판별자\"\"\"\n",
    "    def __init__(self, input_dim, discriminator_dim, pac=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        dim = input_dim * pac\n",
    "        self.pac = pac\n",
    "        self.pacdim = dim\n",
    "        seq = []\n",
    "\n",
    "        for item in list(discriminator_dim):\n",
    "            seq += [Linear(dim, item), LeakyReLU(0.2), Dropout(0.5)]\n",
    "            dim = item # 출력 차원이 다음 입력 차원과 같게 되도록 설정\n",
    "\n",
    "        seq += [Linear(dim, 1)] # 최종 1로 output\n",
    "        self.seq = Sequential(*seq)\n",
    "\n",
    "    def calc_gradient_penalty(self, real_data, fake_data, device='cpu', pac=10, lambda_=10):\n",
    "        \"\"\"Compute the gradient penalty.\"\"\"\n",
    "        alpha = torch.rand(real_data.size(0) // pac, 1, 1, device=device)\n",
    "        alpha = alpha.repeat(1, pac, real_data.size(1))\n",
    "        alpha = alpha.view(-1, real_data.size(1))\n",
    "\n",
    "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "        disc_interpolates = self(interpolates)\n",
    "\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=disc_interpolates, inputs=interpolates,\n",
    "            grad_outputs=torch.ones(disc_interpolates.size(), device=device),\n",
    "            create_graph=True, retain_graph=True, only_inputs=True\n",
    "        )[0]\n",
    "\n",
    "        gradients_view = gradients.view(-1, pac * real_data.size(1)).norm(2, dim=1) - 1\n",
    "        gradient_penalty = ((gradients_view) ** 2).mean() * lambda_\n",
    "\n",
    "        return gradient_penalty\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        \"\"\"Apply the Discriminator to the `input_`.\"\"\"\n",
    "        assert input_.size()[0] % self.pac == 0\n",
    "        return self.seq(input_.view(-1, self.pacdim)) # 입력 레이러를 pac 배로 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 147])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Discriminator 분할\"\"\"\n",
    "input_d = fake_cat\n",
    "input_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = data_dim + self_data_sampler.dim_cond_vec()\n",
    "pac = 10\n",
    "\n",
    "dim = input_dim * pac\n",
    "self_pac = pac\n",
    "self_pacdim = dim\n",
    "self_pacdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1470])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_pacdim = 1470\n",
    "input_d = input_d.view(-1, self_pacdim)\n",
    "input_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = []\n",
    "discriminator_dim = (256, 256)\n",
    "\n",
    "for item in list(discriminator_dim):\n",
    "    seq += [Linear(dim, item), LeakyReLU(0.2), Dropout(0.5)]\n",
    "    dim = item # 출력 차원이 다음 입력 차원과 같게 되도록 설정\n",
    "\n",
    "seq += [Linear(dim, 1)] # 최종 1로 output\n",
    "self_seq = Sequential(*seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1470, out_features=256, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.2)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (4): LeakyReLU(negative_slope=0.2)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_d_output = self_seq(input_d)\n",
    "fake_d_output.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(Module):\n",
    "    \"\"\"Residual layer for the CTGAN\"\"\"\n",
    "\n",
    "    def __init__(self, i, o):\n",
    "        super(Residual, self).__init__()\n",
    "        self.fc = Linear(i, o)\n",
    "        self.bn = BatchNorm1d(o)\n",
    "        self.relu = ReLU()\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        \"\"\"Apply the Residual layer to the input_\"\"\"\n",
    "        out = self.fc(input_)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return torch.cat([out, input_], dim=1) # 기존 입력과 출력을 합침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Residual 분할'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Residual 분할\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Module):\n",
    "    \"\"\"Generate for the CTGAN\"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim, generator_dim, data_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        dim = embedding_dim # 임베딩 차원\n",
    "        seq = []\n",
    "        for item in list(generator_dim):\n",
    "            seq += [Residual(dim, item)]\n",
    "            dim += item\n",
    "        seq.append(Linear(dim, data_dim))\n",
    "        self.seq = Sequential(*seq)\n",
    "\n",
    "    def forward(self, input_):\n",
    "        \"\"\"Apply the Generator to the input_\"\"\"\n",
    "        data = self.seq(input_)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generator 분해'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Generator 분해\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PROPGAN(BaseSynthesizer):\n",
    "    \n",
    "    \"\"\"Args:\n",
    "        - embedding_dim (int): Size of the random sample passed to the Generator. Defaults to 128.\n",
    "        - generator_dim (tuple or list of ints): Size of the output samples for each one of the Residuals. A Residual Layer will be created for each one of the values provided. Defaults to (256, 256).\n",
    "        - discriminator_dim (tuple or list of ints): Size of the output samples for each one of the Discriminator Layers. A Linear Layer will be created for each one of the values provided. Defaults to (256, 256).\n",
    "        - generator_lr (float): Learning rate for the generator. Defaults to 2e-4.\n",
    "        - generator_decay (float): Generator weight decay for the Adam Optimizer. Defaults to 1e-6.\n",
    "        - discriminator_lr (float): Learning rate for the discriminator. Defaults to 2e-4.\n",
    "        - discriminator_decay (float): Discriminator weight decay for the Adam Optimizer. Defaults to 1e-6.\n",
    "        - batch_size (int): Number of data samples to process in each step.\n",
    "        - discriminator_steps (int): Number of discriminator updates to do for each generator update. From the WGAN paper: https://arxiv.org/abs/1701.07875. WGAN paper default is 5. Default used is 1 to match original CTGAN implementation.\n",
    "        - log_frequency (boolean): Whether to use log frequency of categorical levels in conditional sampling. Defaults to ``True``.\n",
    "        - verbose (boolean): Whether to have print statements for progress results. Defaults to ``False``.\n",
    "        - epochs (int): Number of training epochs. Defaults to 300.\n",
    "        - pac (int): Number of samples to group together when applying the discriminator. Defaults to 10.\n",
    "        - cuda (bool): Whether to attempt to use cuda for GPU computation. If this is False or CUDA is not available, CPU will be used. Defaults to ``True``.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim=128, generator_dim=(256, 256), discriminator_dim=(256, 256),\n",
    "                 generator_lr=2e-4, generator_decay=1e-6, discriminator_lr=2e-4,\n",
    "                 discriminator_decay=1e-6, batch_size=500, discriminator_steps=1,\n",
    "                 log_frequency=True, verbose=False, epochs=300, pac=10, cuda=True):\n",
    "        \n",
    "        assert batch_size % 2 ==0\n",
    "\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._generator_dim = generator_dim\n",
    "        self._discriminator_dim = discriminator_dim\n",
    "\n",
    "        self._generator_lr = generator_lr\n",
    "        self._generator_decay = generator_decay\n",
    "        self._discriminator_lr = discriminator_lr\n",
    "        self._discriminator_decay = discriminator_decay\n",
    "\n",
    "        self._batch_size = batch_size\n",
    "        self._discriminator_steps = discriminator_steps\n",
    "        self._log_frequency = log_frequency\n",
    "        self._verbose = verbose\n",
    "        self._epochs = epochs\n",
    "        self.pac = pac\n",
    "\n",
    "        if not cuda or not torch.cuda.is_available():\n",
    "            device = 'cpu'\n",
    "        elif isinstance(cuda, str):\n",
    "            device = cuda\n",
    "        else:\n",
    "            device = 'cuda'\n",
    "\n",
    "        self._device = torch.device(device)\n",
    "\n",
    "        self._transformer = None\n",
    "        self._data_sampler = None\n",
    "        self._generator = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1):\n",
    "        \"\"\"Args:\n",
    "        logits […, num_features]:\n",
    "            Unnormalized log probabilities\n",
    "        tau:\n",
    "            Non-negative scalar temperature\n",
    "        hard (bool):\n",
    "            True인 경우 반환된 샘플은 원-핫 벡터로 이산화되지만 autograd에서는 소프트 샘플인 것처럼 구분됩니다.\n",
    "        dim (int):\n",
    "            softmax가 계산되는 차원\n",
    "\n",
    "        Returns: Gumbel-Softmax 분포의 로짓과 동일한 모양의 샘플링된 텐서.\n",
    "        \"\"\"\n",
    "        if version.parse(torch.__version__) < version.parse('1.2.0'):\n",
    "            for i in range(10):\n",
    "                transformed = functional.gumbel_softmax(logits, tau = tau, hard=hard, eps=eps, dim=dim)\n",
    "                \n",
    "                if not torch.isnan(transformed).any():\n",
    "                    return transformed\n",
    "            raise ValueError('gumbel_softmax returning NaN.')\n",
    "        \n",
    "        return functional.gumbel_softmax(logits, tau=tau, hard=hard, eps=eps, dim=dim)\n",
    "    \n",
    "    def _apply_activate(self, data):\n",
    "        \"\"\"Apply proper activation function to the output of the generator.\"\"\"\n",
    "        data_t = []\n",
    "        st = 0\n",
    "        for column_info in self._transformer.output_info_list:\n",
    "            for span_info in column_info:\n",
    "                if span_info.activation_fn == 'tanh':\n",
    "                    ed = st + span_info.dim\n",
    "                    data_t.append(torch.tanh(data[:, st:ed]))\n",
    "                    st = ed\n",
    "                elif span_info.activation_fn == 'softmax':\n",
    "                    ed = st + span_info.dim\n",
    "                    transformed = self._gumbel_softmax(data[:, st:ed], tau=0.2)\n",
    "                    data_t.append(transformed)\n",
    "                    st = ed\n",
    "                else:\n",
    "                    raise ValueError(f'Unexpected activation function {span_info.activation_fn}.')\n",
    "                \n",
    "        return torch.cat(data_t, dim=1)\n",
    "\n",
    "\n",
    "    def _cond_loss(self, data, c, m):\n",
    "        ## fake data가 들어감\n",
    "        loss = []\n",
    "        st = 0\n",
    "        st_c = 0\n",
    "        for column_info in self._transformer.output_info_list:\n",
    "            for span_info in column_info:\n",
    "                if len(column_info) != 1 or span_info.activation_fn != 'softmax':\n",
    "                    # not discrete column\n",
    "                    st += span_info.dim\n",
    "                else:\n",
    "                    ed = st + span_info.dim\n",
    "                    ed_c = st_c + span_info.dim\n",
    "                    tmp = functional.cross_entropy(\n",
    "                        data[:, st:ed],\n",
    "                        torch.argmax(c[:, st_c:ed_c], dim=1),\n",
    "                        reduction='none'\n",
    "                    )\n",
    "                    loss.append(tmp)\n",
    "                    st = ed\n",
    "                    st_c = ed_c\n",
    "\n",
    "        loss = torch.stack(loss, dim=1)  # noqa: PD013\n",
    "\n",
    "        return (loss * m).sum() / data.size()[0]\n",
    "    \n",
    "    def _validate_discrete_columns(self, train_data, discrete_columns):\n",
    "        # 조건부 벡터를 생성하는 데 사용할 불연속 열 목록입니다.\n",
    "        #  ``train_data``가 Numpy 배열인 경우 이 목록에는 열의 정수 인덱스가 포함되어야 합니다. \n",
    "        # 그렇지 않고 ``pandas.DataFrame``인 경우 이 목록에는 열 이름이 포함되어야 합니다.\n",
    "        if isinstance(train_data, pd.DataFrame):\n",
    "            invalid_columns = set(discrete_columns) - set(train_data.columns)\n",
    "        elif isinstance(train_data, np.ndarray):\n",
    "            invalid_columns = []\n",
    "            for column in discrete_columns:\n",
    "                if column < 0 or column >= train_data.shape[1]:\n",
    "                    invalid_columns.append(column)\n",
    "        else:\n",
    "            raise TypeError('``train_data`` should be either pd.DataFrame or np.array.')\n",
    "\n",
    "        if invalid_columns:\n",
    "            raise ValueError(f'Invalid columns found: {invalid_columns}')\n",
    "        \n",
    "    def fit(self, train_data, discrete_columns = (), epochs = None):\n",
    "        self._validate_discrete_columns(train_data, discrete_columns)\n",
    "\n",
    "        if epochs is None:\n",
    "            epochs = self._epochs\n",
    "        else:\n",
    "            warnings.warn(\n",
    "                ('`epochs` argument in `fit` method has been deprecated and will be removed '\n",
    "                 'in a future version. Please pass `epochs` to the constructor instead'),\n",
    "                DeprecationWarning)\n",
    "        \n",
    "        ## 여기부터 코드를 분해하자\n",
    "        self._transformer = DataTransformer()\n",
    "        self._transformer.fit(train_data, discrete_columns)\n",
    "\n",
    "        train_data = self._transformer.transform(train_data)\n",
    "\n",
    "        self._data_sampler = DataSampler(\n",
    "            train_data,\n",
    "            self._transformer.output_info_list,\n",
    "            self._log_frequency)\n",
    "\n",
    "        data_dim = self._transformer.output_dimensions\n",
    "\n",
    "        self._generator = Generator(\n",
    "            self._embedding_dim + self._data_sampler.dim_cond_vec(),\n",
    "            self._generator_dim,\n",
    "            data_dim\n",
    "        ).to(self._device)\n",
    "\n",
    "        discriminator = Discriminator(\n",
    "            data_dim + self._data_sampler.dim_cond_vec(),\n",
    "            self._discriminator_dim,\n",
    "            pac=self.pac\n",
    "        ).to(self._device)\n",
    "\n",
    "\n",
    "        optimizerG = optim.Adam(\n",
    "            self._generator.parameters(), lr=self._generator_lr, betas=(0.5, 0.9),\n",
    "            weight_decay=self._generator_decay\n",
    "        )\n",
    "\n",
    "        optimizerD = optim.Adam(\n",
    "            discriminator.parameters(), lr=self._discriminator_lr,\n",
    "            betas=(0.5, 0.9), weight_decay=self._discriminator_decay\n",
    "        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PROGAN module.\"\"\"\n",
    "%reload_ext autoreload\n",
    "%autoreload 2 \n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from packaging import version\n",
    "from torch import optim\n",
    "from torch.nn import BatchNorm1d, Dropout, LeakyReLU, Linear, Module, ReLU, Sequential, functional\n",
    "\n",
    "from PROGAN.data_sampler import DataSampler\n",
    "from PROGAN.data_transformer import DataTransformer\n",
    "from PROGAN.synthesizers.base import BaseSynthesizer, random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=128\n",
    "generator_dim=(256, 256)\n",
    "discriminator_dim=(256, 256)\n",
    "generator_lr=2e-4\n",
    "generator_decay=1e-6\n",
    "discriminator_lr=2e-4\n",
    "discriminator_decay=1e-6\n",
    "batch_size=500\n",
    "discriminator_steps=1\n",
    "log_frequency=True\n",
    "verbose=False\n",
    "epochs=300\n",
    "pac=10\n",
    "cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_embedding_dim = embedding_dim\n",
    "self_generator_dim = generator_dim\n",
    "self_discriminator_dim = discriminator_dim\n",
    "\n",
    "self_generator_lr = generator_lr\n",
    "self_generator_decay = generator_decay\n",
    "self_discriminator_lr = discriminator_lr\n",
    "self_discriminator_decay = discriminator_decay\n",
    "\n",
    "self_batch_size = batch_size\n",
    "self_discriminator_steps = discriminator_steps\n",
    "self_log_frequency = log_frequency\n",
    "self_verbose = verbose\n",
    "self_epochs = epochs\n",
    "self_pac = pac\n",
    "\n",
    "if not cuda or not torch.cuda.is_available():\n",
    "    device = 'cpu'\n",
    "elif isinstance(cuda, str):\n",
    "    device = cuda\n",
    "else:\n",
    "    device = 'cuda'\n",
    "\n",
    "self_device = torch.device(device)\n",
    "\n",
    "self_transformer = None\n",
    "self_data_sampler = None\n",
    "self_generator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
       "0           M            Y               Y             0          427500.0   \n",
       "1           M            Y               Y             0          427500.0   \n",
       "2           M            Y               Y             0          427500.0   \n",
       "3           M            Y               Y             0          427500.0   \n",
       "4           M            Y               Y             0          427500.0   \n",
       "\n",
       "  NAME_INCOME_TYPE NAME_EDUCATION_TYPE NAME_FAMILY_STATUS NAME_HOUSING_TYPE  \\\n",
       "0          Working    Higher education     Civil marriage  Rented apartment   \n",
       "1          Working    Higher education     Civil marriage  Rented apartment   \n",
       "2          Working    Higher education     Civil marriage  Rented apartment   \n",
       "3          Working    Higher education     Civil marriage  Rented apartment   \n",
       "4          Working    Higher education     Civil marriage  Rented apartment   \n",
       "\n",
       "   DAYS_BIRTH  DAYS_EMPLOYED  FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  \\\n",
       "0      -12005          -4542           1                1           0   \n",
       "1      -12005          -4542           1                1           0   \n",
       "2      -12005          -4542           1                1           0   \n",
       "3      -12005          -4542           1                1           0   \n",
       "4      -12005          -4542           1                1           0   \n",
       "\n",
       "   FLAG_EMAIL OCCUPATION_TYPE  CNT_FAM_MEMBERS  MONTHS_BALANCE  STATUS  \n",
       "0           0             NaN                2               0      -1  \n",
       "1           0             NaN                2              -1      -1  \n",
       "2           0             NaN                2              -2      -1  \n",
       "3           0             NaN                2              -3      -1  \n",
       "4           0             NaN                2              -4      -1  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('REAL_DATASETS/Credit_merge_data.csv')\n",
    "# 여기서 discrete_columns는 리스트 형태로 다 분해된 형태임\n",
    "# discrete_columns = 'CODE_GENDER,FLAG_OWN_CAR,FLAG_OWN_REALTY,NAME_INCOME_TYPE,NAME_EDUCATION_TYPE,NAME_FAMILY_STATUS,NAME_HOUSING_TYPE,FLAG_MOBIL,FLAG_WORK_PHONE,FLAG_PHONE,FLAG_EMAIL,OCCUPATION_TYPE,STATUS',\n",
    "\n",
    "\"\"\"범주형 변수 분할하기\"\"\"\n",
    "d_list = []\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].dtypes == 'O':\n",
    "        d_list.append(col)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "d2_list = ['FLAG_MOBIL','FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS','STATUS']\n",
    "d_list = d_list + d2_list\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_discrete_columns(train_data, discrete_columns):\n",
    "    \"\"\"Check whether ``discrete_columns`` exists in ``train_data``.\n",
    "\n",
    "    Args:\n",
    "        train_data (numpy.ndarray or pandas.DataFrame):\n",
    "            Training Data. It must be a 2-dimensional numpy array or a pandas.DataFrame.\n",
    "        discrete_columns (list-like):\n",
    "            List of discrete columns to be used to generate the Conditional\n",
    "            Vector. If ``train_data`` is a Numpy array, this list should\n",
    "            contain the integer indices of the columns. Otherwise, if it is\n",
    "            a ``pandas.DataFrame``, this list should contain the column names.\n",
    "    \"\"\"\n",
    "    if isinstance(train_data, pd.DataFrame):\n",
    "        invalid_columns = set(discrete_columns) - set(train_data.columns)\n",
    "    elif isinstance(train_data, np.ndarray):\n",
    "        invalid_columns = []\n",
    "        for column in discrete_columns:\n",
    "            if column < 0 or column >= train_data.shape[1]:\n",
    "                invalid_columns.append(column)\n",
    "    else:\n",
    "        raise TypeError('``train_data`` should be either pd.DataFrame or np.array.')\n",
    "\n",
    "    if invalid_columns:\n",
    "        raise ValueError(f'Invalid columns found: {invalid_columns}')\n",
    "\n",
    "# 여기서 discrete_columns는 리스트 형태로 다 분해된\n",
    "_validate_discrete_columns(train_data = train_data, discrete_columns = discrete_columns[0].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(777715, 76)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1. 데이터 변환\n",
    "self_transformer = DataTransformer()\n",
    "self_transformer.fit(train_data, d_list)\n",
    "train_data = self_transformer.transform(train_data)\n",
    "train_data.shape # (전체 관측치, 변환된 변수 크기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dim:  76\n"
     ]
    }
   ],
   "source": [
    "# 원핫인코딩 된 총 변수의 차원\n",
    "data_dim = self_transformer.output_dimensions\n",
    "print('data_dim: ', data_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 노이즈 사이즈 : torch.Size([500, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 128])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 2. 입력 노이즈를 만들기 위한 크기 생성\n",
    "mean = torch.zeros(self_batch_size, self_embedding_dim, device=self_device)\n",
    "std = mean + 1\n",
    "print('입력 노이즈 사이즈 :', mean.shape)\n",
    "std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch 1555\n"
     ]
    }
   ],
   "source": [
    "### 3. iteration 생성\n",
    "steps_per_epoch = max(len(train_data) // self_batch_size, 1)\n",
    "print('steps_per_epoch', steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 노이즈 : torch.Size([500, 128])\n",
      "조건 벡터 : 4\n"
     ]
    }
   ],
   "source": [
    "### 4. 노이즈 생성\n",
    "fakez = torch.normal(mean = mean, std = std)\n",
    "print('입력 노이즈 :', fakez.shape)\n",
    "\n",
    "# 조건 생성|\n",
    "self_data_sampler = DataSampler(\n",
    "    train_data,\n",
    "    self_transformer.output_info_list,\n",
    "    self_log_frequency)\n",
    "\n",
    "condvec = self_data_sampler.sample_condvec(self_batch_size)\n",
    "print('조건 벡터 :', len(condvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 : torch.Size([500, 71])\n",
      "m1 : torch.Size([500, 14])\n",
      "col : (500,)\n",
      "opt : (500,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "- cond (batch x #categories): The conditional vector.\n",
    "- mask (batch x #discrete columns): A one-hot vector indicating the selected discrete column.\n",
    "- discrete column id (batch): Integer representation of mask.\n",
    "- category_id_in_col (batch): Selected category in the selected discrete column. \"\"\"\n",
    "\n",
    "c1, m1, col, opt = condvec\n",
    "c1 = torch.from_numpy(c1)\n",
    "m1 = torch.from_numpy(m1)\n",
    "print('c1 :', c1.shape)\n",
    "print('m1 :', m1.shape)\n",
    "print('col :', col.shape)\n",
    "print('opt :', opt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perm : (500,)\n",
      "real : (500, 76)\n"
     ]
    }
   ],
   "source": [
    "# 판별자에 넣기 전 섞음\n",
    "perm = np.arange(self_batch_size)\n",
    "print('perm :', perm.shape)\n",
    "\n",
    "np.random.shuffle(perm)\n",
    "real = self_data_sampler.sample_data(self_batch_size, col[perm], opt[perm])\n",
    "c2 = c1[perm]\n",
    "print('real :', real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Module):\n",
    "    \"\"\"Discriminator for the CTGAN.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, discriminator_dim, pac=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        dim = input_dim * pac # data_dim*10\n",
    "        self.pac = pac # 10\n",
    "        self.pacdim = dim # 1280\n",
    "        seq = []\n",
    "        for item in list(discriminator_dim):\n",
    "            seq += [Linear(dim, item), LeakyReLU(0.2), Dropout(0.5)]\n",
    "            dim = item\n",
    "\n",
    "        seq += [Linear(dim, 1)]\n",
    "        self.seq = Sequential(*seq)\n",
    "\n",
    "    def calc_gradient_penalty(self, real_data, fake_data, device='cpu', pac=10, lambda_=10):\n",
    "        \"\"\"Compute the gradient penalty.\"\"\"\n",
    "        alpha = torch.rand(real_data.size(0) // pac, 1, 1, device=device)\n",
    "        alpha = alpha.repeat(1, pac, real_data.size(1))\n",
    "        alpha = alpha.view(-1, real_data.size(1))\n",
    "\n",
    "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "        disc_interpolates = self(interpolates)\n",
    "\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=disc_interpolates, inputs=interpolates,\n",
    "            grad_outputs=torch.ones(disc_interpolates.size(), device=device),\n",
    "            create_graph=True, retain_graph=True, only_inputs=True\n",
    "        )[0]\n",
    "\n",
    "        gradients_view = gradients.view(-1, pac * real_data.size(1)).norm(2, dim=1) - 1\n",
    "        gradient_penalty = ((gradients_view) ** 2).mean() * lambda_\n",
    "\n",
    "        return gradient_penalty\n",
    "\n",
    "    def forward(self, input_):\n",
    "        \"\"\"Apply the Discriminator to the `input_`.\"\"\"\n",
    "        assert input_.size()[0] % self.pac == 0\n",
    "        return self.seq(input_.view(-1, self.pacdim))\n",
    "\n",
    "\n",
    "class Residual(Module):\n",
    "    \"\"\"Residual layer for the CTGAN.\"\"\"\n",
    "\n",
    "    def __init__(self, i, o):\n",
    "        super(Residual, self).__init__()\n",
    "        self.fc = Linear(i, o)\n",
    "        self.bn = BatchNorm1d(o)\n",
    "        self.relu = ReLU()\n",
    "\n",
    "    def forward(self, input_):\n",
    "        \"\"\"Apply the Residual layer to the `input_`.\"\"\"\n",
    "        out = self.fc(input_)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return torch.cat([out, input_], dim=1) # residual connection이어서 원래의 값이 concat됨\n",
    "\n",
    "\n",
    "class Generator(Module):\n",
    "    \"\"\"Generator for the CTGAN.\"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim, generator_dim, data_dim): # data_dim: 원핫인코딩을 포함한 transform된 모든 변수의 크기\n",
    "        super(Generator, self).__init__()\n",
    "        dim = embedding_dim\n",
    "        seq = []\n",
    "        for item in list(generator_dim):\n",
    "            seq += [Residual(dim, item)] # Residual : Linear -> BN -> ReLU\n",
    "            dim += item # residual connection이어서 원래의 값이 concat 되기에 Linear의 input 차원을 늘려줘야 함\n",
    "        seq.append(Linear(dim, data_dim))\n",
    "        self.seq = Sequential(*seq)\n",
    "\n",
    "    def forward(self, input_):\n",
    "        \"\"\"Apply the Generator to the `input_`.\"\"\"\n",
    "        data = self.seq(input_)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_embedding_dim + self_data_sampler.dim_cond_vec() : 199\n",
      "generator_dim : (256, 256)\n",
      "dim : 128\n",
      "data_dim : 76\n"
     ]
    }
   ],
   "source": [
    "### 5. 생성자 입력\n",
    "self_generator = Generator(\n",
    "    self_embedding_dim + self_data_sampler.dim_cond_vec(), # embedding_dim\n",
    "    self_generator_dim, # generator_dim\n",
    "    data_dim # data_dim\n",
    ")\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    data_dim + self_data_sampler.dim_cond_vec(),\n",
    "    self_discriminator_dim,\n",
    "    pac=self_pac\n",
    ")\n",
    "\n",
    "print('self_embedding_dim + self_data_sampler.dim_cond_vec() :', self_embedding_dim + self_data_sampler.dim_cond_vec())\n",
    "print('generator_dim :', generator_dim)\n",
    "print('dim :', embedding_dim)\n",
    "print('data_dim :', data_dim)\n",
    "\n",
    "\n",
    "dim = embedding_dim\n",
    "seq = []\n",
    "for item in list(generator_dim):\n",
    "    seq += [Residual(dim, item)]\n",
    "    dim += item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (seq): Sequential(\n",
       "    (0): Residual(\n",
       "      (fc): Linear(in_features=199, out_features=256, bias=True)\n",
       "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (fc): Linear(in_features=455, out_features=256, bias=True)\n",
       "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Linear(in_features=711, out_features=76, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_data_sampler.dim_cond_vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (seq): Sequential(\n",
       "    (0): Linear(in_features=1470, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 128])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 4. 노이즈 생성\n",
    "fakez = torch.normal(mean = mean, std = std).cpu()\n",
    "fakez.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, m1, col, opt = condvec\n",
    "c1 = torch.from_numpy(c1).cpu()\n",
    "m1 = torch.from_numpy(m1).cpu()\n",
    "fakez = torch.cat([fakez, c1], dim=1) # 조건과 노이즈 합치기\n",
    "print(fakez.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 71])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(c1.shape)\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3,  0, 18,  0,  6,  4,  8, 16,  1,  3,  0,  1,  1, 11,  4,  1,  0,\n",
       "        8,  0, 17,  1,  2,  1,  0,  0,  0,  1,  3,  0,  1,  0,  1,  1,  2,\n",
       "        5,  5,  2,  1,  0,  1,  0,  2,  1,  0,  1,  0,  7,  1,  6,  0,  2,\n",
       "        3,  0,  0,  1,  0,  0,  4,  0,  1,  1,  0,  0,  1,  1,  1,  0,  0,\n",
       "        1,  0,  2,  0,  0,  2,  0,  0,  0,  0,  3,  0,  1,  1,  0,  0,  4,\n",
       "       10,  0,  2,  6,  0,  2,  0,  1,  0,  3,  2,  0,  0,  0,  3,  0,  1,\n",
       "        3,  1,  4,  0,  3,  1,  1,  2,  1,  1,  3,  1,  1,  0,  1,  1,  1,\n",
       "        1,  1,  1, 18,  3,  1,  1,  3,  3,  1, 18,  1,  0,  1,  0,  1,  0,\n",
       "        0,  2,  0,  1,  3,  3,  1,  0,  4,  1,  0,  1,  0,  0,  6,  0,  2,\n",
       "        0,  1,  0,  3,  1,  0,  4,  1,  3,  0,  1,  6,  6,  0, 13,  0,  2,\n",
       "        4,  0,  1,  1,  0,  1,  1,  1,  1,  4,  0,  1,  2,  2,  0,  0, 18,\n",
       "        0,  0,  0,  0,  0,  0,  4,  0,  4,  3,  1,  3,  9,  0,  0,  0,  1,\n",
       "        1, 15,  2,  1,  0,  0,  0,  0,  0,  0,  1,  6,  0,  1, 11,  0,  0,\n",
       "        0,  1,  0,  0,  0,  0,  4,  9,  1,  1,  0,  2,  6,  1,  0,  0,  0,\n",
       "        0,  1,  1,  4,  0,  5,  1,  1,  1,  3,  0,  1,  3,  0,  1,  0,  0,\n",
       "       18,  4,  5,  0,  1,  2,  0,  0,  0,  1,  2,  1,  1,  0,  1,  1,  1,\n",
       "        3,  2,  3,  0,  0, 14,  3,  1,  1,  0,  3,  1,  1, 18,  1,  7,  1,\n",
       "        1,  4,  2,  1,  4,  1,  1,  1,  1, 16,  4,  1,  4,  0,  0,  3,  7,\n",
       "        1,  0,  1,  0,  8,  0,  4,  4, 11,  0,  6,  1,  3,  1,  2,  0,  1,\n",
       "        1,  0,  2,  5,  3,  2,  8,  0,  1,  3,  1,  1, 18,  6,  1,  1,  4,\n",
       "       17,  0,  0,  0,  5,  2,  0,  3,  0,  3,  1,  1,  4,  4,  1,  0,  1,\n",
       "        0,  1,  5,  1,  1,  3,  4,  1,  0,  2,  0,  1,  1,  5,  1,  1,  1,\n",
       "        2,  3, 16,  1,  0,  2,  0,  0,  3,  4,  0,  1,  3,  1,  0,  1,  0,\n",
       "        0,  1,  1,  1,  1,  1,  1,  1,  0,  0,  2,  1,  0,  0,  0,  2,  2,\n",
       "        1, 11,  0,  2,  0,  1,  1,  1,  4,  3,  0,  5,  0,  0,  0,  2,  1,\n",
       "        0,  1,  1,  1,  1,  4,  1,  1,  5,  2,  1,  0,  0,  1,  0,  4,  0,\n",
       "        0,  1,  1,  0,  2,  2,  3,  0,  3,  1,  1,  1,  3,  1,  5,  1,  6,\n",
       "        0,  0,  2,  0,  3,  1,  2,  4,  0,  0,  0,  0,  5,  4, 18,  0,  0,\n",
       "        2,  0,  1,  2,  1,  0,  0,  0,  4,  1,  0,  0,  0,  0,  3,  5,  1,\n",
       "        0,  1,  0,  1,  6,  2,  1], dtype=int64)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(opt.shape)\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 5, 10, 11,  1, 13,  5, 11, 11,  8,  5,  7,  1,  2, 11, 11, 10,  4,\n",
       "       11, 10, 11,  2, 12, 10,  4,  5,  8,  0,  3,  1, 12,  8,  3, 10,  3,\n",
       "       11, 11,  3, 10,  8,  2,  0,  5,  8, 12,  4,  1, 12,  1, 12, 12,  5,\n",
       "        5,  0,  6, 10,  6, 10,  4, 10,  8,  1,  3, 10, 10,  9,  8,  8,  1,\n",
       "        5,  0, 13,  2,  3, 13,  4,  1,  0,  3,  5,  2, 10,  2,  2,  0,  4,\n",
       "       11, 10,  4, 12,  7,  3,  7,  9,  2,  4, 13,  8,  8,  7,  6,  3,  0,\n",
       "       11,  1,  6,  2,  6,  1, 11,  3,  0,  9,  6, 13,  4,  1,  0,  0,  9,\n",
       "        8,  5,  6, 11,  6,  8,  2, 13,  5,  8, 11,  3,  2,  2,  2,  5,  8,\n",
       "        7, 11,  9,  6, 13,  3,  1,  8,  3,  2,  7, 13,  0,  4, 13,  8, 13,\n",
       "        7,  9,  7,  5,  4,  0,  5,  0, 13, 10,  5, 12, 13,  0, 11,  7,  6,\n",
       "        3,  2, 12,  1,  0,  0,  5,  1,  2,  6,  8,  9, 13, 12, 12,  8, 11,\n",
       "        8,  3, 10,  0,  1,  9,  5,  8,  4,  3, 10,  4, 12,  1,  0, 10,  8,\n",
       "       13, 11,  5,  1,  8,  2,  7,  9,  5,  9,  0, 13,  6,  0, 11,  1, 10,\n",
       "        8,  5,  2,  9,  0, 13, 13, 12,  6, 10,  2, 13, 13,  3,  0, 10,  5,\n",
       "        7,  8,  9,  3,  4, 13,  4,  0, 12,  6,  9,  8, 13,  3,  1,  2,  7,\n",
       "       11,  5, 11,  8,  9,  5,  1,  7, 10,  5, 12,  4, 12,  9,  1,  2,  8,\n",
       "       12,  3, 12,  1,  2, 11,  4, 13,  9,  7,  4,  5,  9, 11,  5, 11, 11,\n",
       "        8,  6,  4,  1,  3, 10,  5,  0, 11, 11, 12, 12,  5,  3,  1, 13, 12,\n",
       "        2,  5,  0,  2, 11,  7,  4,  5, 11,  7, 12,  9, 13,  8, 13,  9,  4,\n",
       "        9,  0, 12, 13,  5,  5, 11,  2,  8,  3,  8,  3, 11, 12,  9,  0, 12,\n",
       "       11,  9,  7,  7, 11,  4, 10, 13,  3, 11,  6,  9,  5, 13,  1,  6,  4,\n",
       "        2, 10,  6,  3, 10,  5, 12,  8,  1,  6,  3,  3,  1, 13,  0, 10, 10,\n",
       "        3,  4, 11,  9, 13,  6, 13, 13,  6, 12,  8,  5, 12,  8,  0, 11,  4,\n",
       "        6,  0,  4,  1,  2,  1,  0,  2,  8,  7,  4,  0,  1,  8,  2,  3,  3,\n",
       "        1, 11,  7,  6, 12,  0,  8,  1,  6,  6,  9, 13, 10, 13, 10,  6,  2,\n",
       "        8,  5,  2,  5,  6,  6,  4,  6, 13,  5,  9,  1,  7,  9,  7,  4,  2,\n",
       "       10,  2,  3,  2,  5,  5,  3,  1,  4, 10, 10,  4, 13,  5, 13,  0, 11,\n",
       "        8,  8, 13, 12,  6,  5,  6,  5,  5,  1,  7,  7,  6,  3, 11,  7, 10,\n",
       "       13,  7,  9,  3,  8,  7,  3,  2,  5,  0,  0,  7,  0,  7, 13,  6,  1,\n",
       "       10,  5,  7,  3, 12,  5,  6])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(col.shape)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([129, 193, 359, 278,  87,  25, 149, 214, 399, 246, 375, 458, 137,\n",
       "       126, 428, 202, 124, 175, 250, 467, 238,  36, 453, 301, 420, 416,\n",
       "        77, 362, 304, 395, 460, 451, 192, 185,   0,  16, 195, 242, 282,\n",
       "        72, 296, 388, 495, 491, 241, 312,  57, 344, 265, 112, 232, 383,\n",
       "       270, 379, 466, 319,  21, 487, 455, 286,  15, 254,  63,  24,  84,\n",
       "        62,  76, 252, 107, 335, 303,  30, 449, 300, 268, 165, 134, 233,\n",
       "       321, 293,  90, 431, 324, 136, 438,  56, 128, 204, 333, 225, 464,\n",
       "       489, 389, 421, 294, 391, 337, 401, 393, 450, 101, 227, 370, 363,\n",
       "       361, 368, 373, 230, 305,  11, 147,   3, 405, 139, 273, 140, 468,\n",
       "       117, 410, 342, 130, 266,  20, 289, 261, 299, 218,  55, 430, 231,\n",
       "       494,  93, 279, 360, 435,  12, 102, 481, 188, 336, 341, 385, 119,\n",
       "       437, 196, 353, 264, 470,  69, 380,  42, 163, 369, 199, 189, 313,\n",
       "       422, 187,  35, 219, 309, 276,  48, 287, 482, 338, 181, 260, 131,\n",
       "       177, 429, 307, 160, 498,  38, 197, 174, 253, 323, 328, 322, 314,\n",
       "       157, 414, 210, 288, 475, 427, 439, 306, 490, 105, 376, 354, 206,\n",
       "        66,  22, 121,  39, 148, 285, 257, 418,  74, 258, 295, 132, 492,\n",
       "        89, 141, 398, 216,  19, 432, 318,  81, 151,   1, 158,  26, 364,\n",
       "       114, 457, 298, 209, 377,  65,  75, 311, 448, 292,  94, 404, 184,\n",
       "        46, 396, 290,   9,  70, 454, 483, 143, 133, 180, 226, 262, 271,\n",
       "       263, 390, 191, 284, 154,  37, 392, 249, 316, 407,  45, 358,  98,\n",
       "       366,  51, 478,  78, 291, 441, 493, 413,  44,   4, 365, 477, 320,\n",
       "       372, 423,  67, 169, 409, 243,  28, 256, 122,  85, 280, 274, 161,\n",
       "        61, 234, 275, 224, 228,  14, 205, 371,   5, 240, 384, 164, 173,\n",
       "       402,  33, 417,  99, 244, 108, 330,  60, 411, 203, 446, 408, 217,\n",
       "       479,  82, 144, 486, 236, 104,  49, 103, 248,  88, 198,  71,   8,\n",
       "       302,  17,  34,  58,  32,  86,  27, 221, 346, 343, 215, 308, 251,\n",
       "       386, 334,  52, 109,  92, 310, 463, 201,  41, 120, 172, 325,  91,\n",
       "       110, 447, 433, 445, 277, 178, 106, 394,  68,  13, 123, 281, 115,\n",
       "       142,  59,  80, 403, 162, 474, 444, 351, 339, 497, 374, 349, 425,\n",
       "       118, 146, 245, 155, 332, 382,  54, 255, 465, 166,  40, 419, 223,\n",
       "       150, 484, 170, 329, 229, 138,  50, 156, 297,  97, 267, 135, 326,\n",
       "       176, 456, 400, 488, 443, 259, 237, 125, 269, 111, 434, 355,  29,\n",
       "       331, 208, 152, 212, 476, 272, 406, 167, 440,  10, 182,  18, 283,\n",
       "        64, 247,   7,   2, 315, 186, 207, 317, 235, 145, 469,  43, 194,\n",
       "         6, 200,  96, 397, 211, 113,  79, 381, 100, 367,  23, 357, 213,\n",
       "       461, 327,  31, 499,  95, 387, 168, 171, 340, 436, 220, 472,  83,\n",
       "        47, 190, 179, 473, 415, 452, 347, 496, 485, 127, 480, 116, 356,\n",
       "       153, 239,  73, 424, 222,  53, 350, 459, 426, 462, 352, 378, 348,\n",
       "       442, 183, 471, 345, 412, 159])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = np.arange(self_batch_size)\n",
    "np.random.shuffle(perm)\n",
    "perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  5,  6,  4,  4,  8,  4,  0,  8, 12,  4, 11, 11, 13,  5, 10,  8,\n",
       "        0, 13,  5,  7,  3,  4,  5, 10,  6,  3,  5, 13,  2,  8, 10,  9,  8,\n",
       "        5,  4,  4,  4,  4,  3,  0,  0,  7,  6,  3,  4,  4, 11, 12,  6, 13,\n",
       "       12,  2,  6,  5,  8, 12,  7,  5,  5, 10,  7, 10,  5,  4, 10,  0,  1,\n",
       "        1, 11,  1,  8,  1, 12,  9, 13,  5, 13,  9,  3,  3,  4,  0,  7,  9,\n",
       "       10,  8, 13,  8,  0,  5,  7, 11, 13, 10,  6,  9,  4,  4,  4,  0, 13,\n",
       "       13, 12, 10,  3, 10, 10, 12,  1, 13,  1,  2,  6,  3, 13,  1,  0,  7,\n",
       "        7,  3,  4,  2,  8,  1, 12, 11,  6,  6,  2,  5,  2, 13,  3,  9,  2,\n",
       "       11,  7,  3, 12,  9,  5,  8,  7,  3, 13,  5,  7,  0, 13,  8,  5,  1,\n",
       "       12, 10,  5, 10,  8, 11,  1,  2,  2, 12, 11,  3,  0,  9,  5,  2,  1,\n",
       "        6,  5,  0,  5,  8, 10,  0,  2,  9,  5,  4, 11,  4,  8,  7, 11, 10,\n",
       "        2,  7,  2, 13,  2, 11,  1,  5,  8, 10,  6,  2,  0, 11, 11,  9,  4,\n",
       "        8,  5,  2,  1,  7,  3,  2,  6, 11,  6, 13,  2,  8, 10,  0,  0,  8,\n",
       "        4,  0, 11,  2,  9,  8,  1,  7,  3,  1,  4,  8, 12, 12,  1,  6,  5,\n",
       "       13, 13,  2,  8,  2,  8, 13,  7,  8, 10,  4,  1,  9,  9, 10,  0,  8,\n",
       "       12,  3,  1, 10,  7,  6,  5,  9,  5,  4,  2, 10,  0,  4, 13,  1,  7,\n",
       "       13, 10,  6,  1,  6, 11, 13,  1,  5, 11, 11,  9, 12, 13,  3,  3,  1,\n",
       "        9, 12, 11, 11,  0,  5,  9,  8, 12,  1,  0,  3,  6,  6,  4, 11,  2,\n",
       "        1,  6,  8,  5,  1,  0,  3,  2,  3,  0, 10,  6, 12,  1,  9, 12,  4,\n",
       "        2,  8,  3, 11, 11, 10, 10, 10,  3,  8, 10,  7, 13,  0,  3, 12,  3,\n",
       "        0,  3,  9, 11,  6,  0,  5,  5, 12, 12,  7,  0,  5, 13,  2, 11,  2,\n",
       "        6,  1,  5, 11,  6,  7,  1,  1,  8, 10,  1, 10,  7,  3,  9, 12, 12,\n",
       "        3, 11,  8,  9,  7,  0,  7,  3,  6, 10, 11,  6,  0,  0, 13,  2, 13,\n",
       "        5,  3, 11,  6,  9,  5,  5, 11,  8, 12,  8, 13,  5, 13,  7,  0,  2,\n",
       "        9,  5,  2,  1,  9,  5,  6, 12,  8,  8, 13,  5, 13, 12,  3, 11,  4,\n",
       "        7, 13, 10,  5,  9,  6, 11, 11,  7, 11,  1,  9,  0,  2,  7, 12,  8,\n",
       "       11,  1,  8,  0,  9, 13,  2, 13,  3,  3,  4,  2,  9, 13,  5,  3,  6,\n",
       "       13,  8,  7,  2, 11,  1, 10,  3,  0,  1,  0,  6, 11,  1, 10, 13,  3,\n",
       "        0,  5,  8,  0,  4,  7,  8, 13,  2,  5,  6,  6,  8,  5, 12,  5, 13,\n",
       "        3, 10, 12,  6,  4, 12,  5])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake : torch.Size([500, 76])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (seq): Sequential(\n",
       "    (0): Residual(\n",
       "      (fc): Linear(in_features=199, out_features=256, bias=True)\n",
       "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (fc): Linear(in_features=455, out_features=256, bias=True)\n",
       "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Linear(in_features=711, out_features=76, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fake 데이터 생성\n",
    "fake = self_generator(fakez)\n",
    "print('fake :', fake.shape)\n",
    "self_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fakeact : torch.Size([500, 76])\n"
     ]
    }
   ],
   "source": [
    "def _gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1):\n",
    "    if version.parse(torch.__version__) < version.parse('1.2.0'):\n",
    "        for i in range(10):\n",
    "            transformed = functional.gumbel_softmax(logits, tau=tau, hard=hard,\n",
    "                                                    eps=eps, dim=dim)\n",
    "            if not torch.isnan(transformed).any():\n",
    "                return transformed\n",
    "        raise ValueError('gumbel_softmax returning NaN.')\n",
    "\n",
    "    return functional.gumbel_softmax(logits, tau=tau, hard=hard, eps=eps, dim=dim)\n",
    "\n",
    "\n",
    "def _apply_activate(data):\n",
    "    \"\"\"Apply proper activation function to the output of the generator.\"\"\"\n",
    "    data_t = []\n",
    "    st = 0\n",
    "    for column_info in self_transformer.output_info_list:\n",
    "        for span_info in column_info:\n",
    "            if span_info.activation_fn == 'tanh':\n",
    "                ed = st + span_info.dim\n",
    "                data_t.append(torch.tanh(data[:, st:ed]))\n",
    "                st = ed\n",
    "            elif span_info.activation_fn == 'softmax':\n",
    "                ed = st + span_info.dim\n",
    "                transformed = _gumbel_softmax(data[:, st:ed], tau=0.2)\n",
    "                data_t.append(transformed)\n",
    "                st = ed\n",
    "            else:\n",
    "                raise ValueError(f'Unexpected activation function {span_info.activation_fn}.')\n",
    "    return torch.cat(data_t, dim=1)\n",
    "\n",
    "\n",
    "fakeact = _apply_activate(fake) # 각 변수에 맞는 활성화 함수 적용\n",
    "print('fakeact :', fakeact.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 76)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real : torch.Size([500, 76])\n"
     ]
    }
   ],
   "source": [
    "# 실제 데이터 넘파이 변환\n",
    "real = torch.from_numpy(real) # 실제 데이터 텐서로 변환\n",
    "print('real :', real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_cat : torch.Size([500, 147])\n",
      "real_cat : torch.Size([500, 147])\n"
     ]
    }
   ],
   "source": [
    "### 6. 판별자에 넣기 전 조건 합치기\n",
    "fake_cat = torch.cat([fakeact, c1], dim=1)\n",
    "c2 = c1[perm]\n",
    "real_cat = torch.cat([real, c2], dim=1).float()\n",
    "\n",
    "print('fake_cat :', fake_cat.shape)\n",
    "print('real_cat :', real_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.4029e-01, 3.5971e-01, 9.9655e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.0000e+00, 9.0019e-10, 2.0393e-05,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.0612e-04, 9.9989e-01, 2.0905e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [1.1293e-01, 8.8707e-01, 1.0039e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.8453e-04, 9.9982e-01, 1.7269e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [3.7373e-03, 9.9626e-01, 1.8217e-05,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_fake : torch.Size([50, 1])\n",
      "y_real : torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "### 7. 판별자에 넣기\n",
    "y_fake = discriminator(fake_cat)\n",
    "y_real = discriminator(real_cat)\n",
    "\n",
    "print('y_fake :', y_fake.shape)\n",
    "print('y_real :', y_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0530],\n",
       "        [-0.0316],\n",
       "        [-0.0158],\n",
       "        [-0.0063],\n",
       "        [-0.1810],\n",
       "        [-0.1155],\n",
       "        [-0.0839],\n",
       "        [-0.0264],\n",
       "        [-0.0123],\n",
       "        [-0.1165],\n",
       "        [-0.0673],\n",
       "        [-0.1692],\n",
       "        [-0.1835],\n",
       "        [-0.0229],\n",
       "        [-0.0661],\n",
       "        [-0.0883],\n",
       "        [-0.0593],\n",
       "        [-0.2608],\n",
       "        [-0.1088],\n",
       "        [ 0.0652],\n",
       "        [ 0.0277],\n",
       "        [-0.0012],\n",
       "        [-0.1454],\n",
       "        [-0.1742],\n",
       "        [-0.0669],\n",
       "        [-0.1389],\n",
       "        [-0.0347],\n",
       "        [-0.1413],\n",
       "        [-0.0533],\n",
       "        [-0.1598],\n",
       "        [-0.1590],\n",
       "        [-0.0612],\n",
       "        [-0.0693],\n",
       "        [-0.0335],\n",
       "        [-0.0585],\n",
       "        [-0.1004],\n",
       "        [-0.0816],\n",
       "        [-0.0450],\n",
       "        [-0.0221],\n",
       "        [-0.1716],\n",
       "        [-0.1400],\n",
       "        [-0.0153],\n",
       "        [ 0.0270],\n",
       "        [ 0.0473],\n",
       "        [-0.1691],\n",
       "        [ 0.0467],\n",
       "        [-0.2055],\n",
       "        [ 0.0329],\n",
       "        [-0.1783],\n",
       "        [-0.0363]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (seq): Sequential(\n",
       "    (0): Linear(in_features=1470, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
